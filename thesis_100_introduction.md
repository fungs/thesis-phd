# Synopsis

## Metagenomics

Metagenomics is a more recent variant of genomics which pursues medical or ecological questions at the scale of microbial communities using nucleotide sequencing. In contrast to microbial genomics, which is focused on single strains  traditionally grown in lab cultures before genome sequencing, the metagenomic approach applies direct sampling from a natural ecosystem without cultivation. Microbes form so-called communities in their micro-environment because they interact, for instance by symbiosis (e.g. sharing metabolites) or competition (e.g. for food). Such a community may consist of hundreds or thousands of different species, which are connected by complex interactions [@BerryDeciphering2014; @FuhrmanMarine2015]. It is the principal interest of microbial ecology to understand these interaction networks, which make it difficult to isolate and grow the organisms on culture medium because the specific cultivation conditions cannot be reproduced [@RiesenfeldMetagenomics2004; @StewartGrowing2012]. However, by extracting and sequencing environmental DNA directly after sampling, one can capture the genomes of all community members, although in a highly fractional and usually incomplete form. One could say that current metagenomics trades the species-level resolution and the completeness of very few genomes for a higher level view on the genes in a community. The metagenome, a term coined in the early 2000 [@RondonCloning2000; @RiesenfeldMetagenomics2004; @TysonCommunity2004], stands for all the genes in a microbial community. These genes determine the ecological functions of the community members through the proteins they encode. Metagenome sequencing can thus collect new environmental genes and discover protein functions with potential use in medicine and biotechnology, and provides a way to understand the microbial interactions within diverse ecosystems. It has been used to study many different environments ([@fig:metagenomes_environments]).

![Microbial environments extracted from 10,043 publication titles (2011-2017) positioned by cooccurence in publication titles. The articles were selected by topic "metagenomics" and the corresponding metadata downloaded from Europe PMC (europepmc.org). The titles were then reduced to environment-related words and these were grouped by the number of cooccurences using Gephi (gephi.org) with a force-directed layout and subsequent annotation of clusters. Three major clusters emerge, relating to aquatic environments, soil and plant biomass degradation and (human) host-related environments.](figure/metagenome_title_clusters.pdf "Microbial environments extracted from 8211 publication titles"){#fig:metagenomes_environments}

Early metagenomic studies have impressively demonstrated the potential of this new approach. For instance, new antibiotics and antibiotic resistance genes were identified [@GillespieIsolation2002; @RiesenfeldUncultured2004]. An ocean survey [@VenterEnvironmental2004] revealed hundreds of new rhodopsin-like genes in seawater environments (rhodopsin is an essential protein to sensing light) among over 1.2 million novel genes. In the following, numerous micro-environments were explored to provide a census of genes and species, many of them previously unknown. For the various sites in and on the human body, which represent well-studied environments due to medical applications, the resulting data provided new insight into the interactions between the human host and its so-called microbiome. For instance abnormal microbial colonization of the gut was observed with chronic inflammation [@QinHuman2010]. Although most investigations have focused on the bacteria, the best known domain in the microbial tree of life, metagenomics has also been used to study the genes of archaea, microscopic eukaryotes, viruses and genetic elements like plasmids [@HugenholtzMicrobiology2008; @GarrettMetagenomic2010; @CuvelierTargeted2010], which helped to broaden the view on the global genetic repertoire of life and its evolution.

### DNA sequencing

Past and present progress in the field of metagenomics is tightly coupled to the development of next-generation sequencing technologies (NGS). While earlier studies were based on the Sanger sequencing technology [@WommackMetagenomics2008], the underlying chemistry has been subject to many improvements, such as the engineering of highly parallel reaction and detection procedures. This has led to an considerable drop in overall time and cost of nucleotide sequencing [@DrogeTaxonomic2012]. The first sequencing approaches in metagenomics targeted well studied single genes, predominantly the bacterial and archaeal gene of the ribosomal 16S subunit [@QuinceRational2008; @HamadyMicrobial2009], which is a good taxonmic marker because it contains both conserved and divergent regions. In this context, sequences identity thresholds were applied to define operational taxonomic units (OTUs) as an approximate species replacement. The variable regions were amplified in a polymerase chain reaction (PCR) before sequencing and are therefore called amplicons. Using this selective approach reduced the amount of target DNA from millions of bases per genome to a few hundreds while giving estimates of genetic species diversity. Amplicon sequencing is still in use and represents a cost-effective way to study the taxonomic composition and taxon abundances. However, it cannot be used to discover the functional potential unless the corresponding genome sequences are available for consideration. To target novel community genomes, universal sequencing primers initiate sequencing at random starting positions on the DNA strands. This approach is called shotgun sequencing due to the fact that the reads are more or less randomly scattered over the entire genome sequence. With a sufficient number of reads, metagenomic shotgun sequencing can cover most genes and continues to evolve together with next-generation sequencing platforms, but also with respect to experimental protocols and data analysis methods. A major limitation of current sequencing technologies is the length of the primary sequencing products (reads). In particular, the currently dominating Illumina sequencing platform produces reads which are still much shorter than typical genes [@DrogeTaxonomic2012] so that overlapping reads are typically assembled to form longer contiguous sequences (contigs) [@MillerAssembly2010]. New technologies such as PacBio and Oxford Nanopore sequencing yield longer reads but have larger error rates and higher costs compared to Illumina, which limits their current use in metagenomics [@GoodwinComing2016].

Metagenomic studies have highlighted the advantages of metagenomic over the traditional sequencing approach using isolated and cultured strains. The genomes of environmental microorganisms were found to be much more genetically diverse than those of corresponding lab strains [@TysonCommunity2004; @HandelsmanMetagenomics2004], which essentially represent clones of a single cell. Researchers also become more aware of the fact that genetic data collections are strongly biased towards taxa which are easily grown in lab cultures and which are of medical relevance, leaving many black spots in the microbial tree of life [@TysonCommunity2004; @WuPhylogenydriven2009]. Using the exploratory metagenomics approach, there is no need to narrow the focus on certain species and to hypothesize about the role of these organisms in their environment beforehand. The bird's eye view on the genes helps to identify mutual dependencies, such as pathways that are connected between different genomes [@PonomarovaMetabolic2015], and to associate new functions and new species. Apart from this, direct sequencing also creates new problems. Some sequencing platforms introduce a bias related to the nucleotide composition [@DohmSubstantial2008], which may affect the analysis. In general, it is difficult to distinguish sequencing errors from natural genetic variation, which, in some cases, could lead to wrong conclusions such as inflated microbial diversity estimates [@QuinceAccurate2009; @KuninWrinkles2010]. Another problem with this sequence heterogeneity is that longer genome sequences often fail to assemble due to the natural and artificial nucleotide variations in the reads [@MelstedEfficient2011; @PellScaling2012]. Typical metagenome data therefore contain many incomplete genes whose origin and functional role needs to be determined.

### The role of computer programs

Today's genomic data are ubiquitous and abundant due to high-throughput nucleotide sequencing. Consequently, the data generation marks a starting point of knowledge discovery, making modern metagenomics in large part a data-driven science in which algorithms have replaced lab techniques to sort and analyze genetic material. Metagenome data are large (because they represent many genomes) and require extensive processing to deal with the phylogenetic and genetic diversity in the sample. It is convenient to divide the downstream processing of raw sequencing data into three consecutive steps which are illustrated in [@fig:metagenome_processing_steps]: (a) sequence processing specific to the sequencing platform and often performed by proprietary software; (b) metagenome analysis and reduction to non-redundant draft genome sequences; (c) algorithms to study the individual genomes and how they interact. Step (a) applies not only to metagenomics but to all sciences using nucleotide sequencing and, from a practical perspective, decouples downstream algorithms from the specifics of sequencing technology and its development. The work presented in this thesis contributes to step (b), to prepare the data for use in downstream algorithms in step (c), which are tailored to the biological questions.

![Major steps in metagenome data processing. Typical processing consists of three consecutive levels: (a) read processing (b) contig analysis and binning and (c) the analysis at the genome level.](figure/metagenome_processing_steps.pdf "Major steps in metagenome data processing"){#fig:metagenome_processing_steps}

An important step following nucleotide sequencing is the assembly of overlapping reads into longer contigs. For this, many reads must be sequenced to cover the corresponding genome positions. In current Illumina sequencing protocols, pairs of reads are typically linked in the experimental library preparation [@GoodwinComing2016] to capture their relative orientation and approximate distance (insert size). This information helps to construct longer contigs, because otherwise repetitive regions or homologous genes which are longer than the read length cannot be distinguished if they cause loops in the assembly graph [@GhuryeMetagenomic2016]. When the read coverage drops for intermediate regions, the corresponding genomes also break into multiple shorter contigs. Existing assemblers for isolate genome assembly, which has been available for a long time [@SuttonTigr1995; @HuangCap31999], has been adjusted to assemble metagenomes [@GhuryeMetagenomic2016]. Metagenome assemblers must cope with the natural genetic variance of strains compared to clonal DNA and must also take into account that, due to different abundances in the sample, the number of genome copies varies considerably among the species or strains, resulting in a large range of read coverages. The assembly of reads for complex communities is considered an algorithmic challenge, but often reduces the amount of data considerably and produces a fraction of longer contigs which represent full or partial genes. Assembly is therefore a reasonable first step towards recovering the full genome sequence of environmental microbes. In the workflow [@fig:metagenome_processing_steps], the assembly bridges steps (a) and (b) because the input sequencing reads have a length and error profile which is specific to the sequencing platform but the output contigs represent generic sequences with most errors removed.

Genomic methods frequently operate on complete genome sequences, for instance inferring functional models for specific organisms [@PriceGenomescale2004]. Gene regions are identified, their corresponding protein sequences determined and hypothetical pathways constructed. To do similar in metagenomics, contigs are often grouped to form hypothetical draft genomes, called genome bins. The binning process tries to reconstruct the genomes and solves a problem which, at first, appears very similar to that of metagenome assembly. However, contig binning is usually independent of the sequencing platform (it makes no use of sequencing quality) and considers information which assembly programs ignore (e.g. gene annotations). Both steps can be iterated in a feedback cycle ([@fig:assembly_binning_cycle]) to improve the quality of the resulting genomes [@AlbertsenGenome2013]. Metagenome binning connects step (b) and (c) in [@fig:metagenome_processing_steps] because it reduces the data to individual genomes. This thesis presents algorithms related to the binning problem which I, in collaboration with my colleagues, developed and published during my doctoral studies.

![Assembly and binning cycle for genome reconstruction in metagenomes. Longer contigs yield better preliminary genome bins and when collecting the reads within a bin, these are more specific to the genome and lead to better assembly.](figure/assembly_binning_cycle.pdf "Assembly and binning cycle"){#fig:assembly_binning_cycle}

### Community transcriptomics, proteomics and metabolomics

Nucleotide gene sequences can only tell about potential functions of an organism but there may be much more to discover. For instance, we are interested in seeing genes which are actively expressed and to understand how the gene expression is regulated within the community. The proteins, for which the genes code, are the acting agents in any organism, so it is most important to determine the functional role of proteins, how they interact, and which metabolites they target and mediate. Corresponding experimental techniques for transcriptome, proteome and metabolome analysis are being adapted and applied to microbial communities [@TurnbaughInvitation2008; @AguiarpulidoMetagenomics2016]. Such data representing cellular activity are most informative when they can be linked to the corresponding gene sequences and genomes so that their regulation and coupling can be studied in detail. The genomes bins derived by metagenome binning can form the basis to build models which can integrate information from other experiments, for instance measuring the current state of a community in terms of genome activity, micro-evolution or population dynamics.
