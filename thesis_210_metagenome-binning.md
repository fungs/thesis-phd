## Metagenome binning

Metagenome studies can be focused on identifying novel enzymes, mainly driven by biotechnological and medical applications, for instance using functional screening [@UfarteDiscovery2015]. Though, when studying protein-coding genes and their regulation in more detail, it is often beneficial to look at the corresponding genomes to understand the genomic context. One way to collect cells to retrieve a full genome sequence is by physical extraction from the environment or from enrichment cultures. However, it can be difficult to extract specific organisms if there are hundreds or thousands of distinct species, subspecies or operational taxonomic units (OTUs) in a metagenomic sample [@HessMetagenomic2011; @WoykeAssembling2009; @WoykeOne2010]. Furthermore, the cultivation conditions required to produce clone libraries may be unknown, and environmental sequencing of extracted cells with small amounts of DNA is still in its infancy [@MendeImproved2016; @YuMicrofluidicbased2017]. For these reasons, *in-silico* metagenomic methods provide a solid alternative. Metagenome sequence binning is the algorithmic equivalent for reconstructing individual genomes from shotgun metagenome sequence data. Broadly speaking, a genome bin is a set of sequences, usually assembled contigs, which together present the sequenced part of a specific community genome. Capturing these partial genomes allows studying taxa on the level of genes and their associated functions. For an extensive introduction to metagenome binning, see the review article [@DrogeTaxonomic2012] in the appendix of this thesis.

### Binning methodology

Binning represents a machine learning procedure in which class labels (genomes) are assigned to data points (contigs) (see @HastieElements2001, chapter 1, for a comprehensive introduction to these concepts). Most of the different algorithmic approaches to infer genome bins are either a form of data clustering or classification, including combinations of both approaches. Clustering is a so-called unsupervised method, which does not directly take into account external information like available genome sequences. The strength of clustering is that it can group any data to explore their intrinsic structure, being able to group contigs of genomes which have never been seen before. In contrast, classification algorithms utilize categorized (labeled) data, for instance large genome sequence collections, to assign sequences to genome bins. They are said to operate in a supervised manner. By the use of prior knowledge they can be very efficient but a major drawback is the difficulty to handle novel genomes. Clustering and classification methods give complementary results and it is common to combine them, for instance classifying genome bins after clustering or initializing clusters using classification labels [@ImelfortGroopm2014].

### Sequence information for binning

Binning methods can also be categorized by the kind of information they use. Both clustering or classification methods for binning operate on so-called features derived from reads or contigs. These properties inform about genome membership and discriminate contigs of different genomes. Microbial genomes sequences expose a characteristic frequency distribution of short nucleotide motifs [@KarlinCompositional1997] which is frequently used in binning and refered to as the genome or nucleotide composition. The combined relative frequency of guanine and cytosine (GC-content) is a simple way to represent nucleotide composition, and an evolutionary trait of genomes that has long been used to characterize different species. For instance, most Actinobacteria expose a high GC-content. Many methods, however, use short nucleotide motifs consisting of 4 to 7 bases called $k$-mers ($k$ stands for the number of bases). Alternative formulations may use Hidden Markow Models (HMMs) to describe nucleotide composition [@BradyPhymm2009]. The second major feature type for binning is read coverage, the amount of sequencing reads for each assembled contig. Since contigs are constructed by stacking (aligning) overlapping reads, each nucleotide position of a resulting contig must be covered by at least a single read, but typically many more. Following random shotgun sequencing with universal primers, the expected number of reads covering a single position is approximately proportional to the genome copy number in the sequenced sample [@LanderGenomic1988], with a constant factor which depends on the total sequencing effort. Thus contig coverage helps to discriminate genomes with distinct sample abundances, but cannot differentiate between equally abundant genomes. It is therefore desirable to generate multiple metagenome samples of a community for which the genome copy numbers vary differently. This way, each genome has a unique set of genome abundances. Recent studies have shown that genome abundances represent a very informative feature type to obtain genome bins for complex metagenomes, if many varying samples are available [@AlbertsenGenome2013; @AlnebergBinning2014]. Sometimes, binning programs may also employ assembly information such as associated contigs or scaffolds linked by paired reads [@LuCocacola2016], but such information, if available, is more frequently used to link, quality-check or refine genome bins after binning [@PatilTaxonomic2011].

There is a specific class of homology-based classifiers, and an example of such a method is described in [@sec:synopsis_taxator-tk]. These methods employ a two-step procedure, first identifying potential homologs for a contig, for instance by alignment to reference sequences, and second determining a corresponding evolutionary neighborhood. This neighborhood is usually reported by taxonomy, so that each contig is annotated with a taxonomic path. A grouping of contigs by taxa then provides a form of binning but higher-level taxon bins mix contigs from several genomes, if the sample contains more than a single member of this group. Hence, taxonomic classification using sequence similarity can only provide a partial solution to the binning problem. However, such annotation also informs about the taxonomic sample composition and diversity, similar to a 16S gene analysis, and may furthermore be used as secondary features for clustering, for instance to initialize genome clusters [@ImelfortGroopm2014] or to train a classification model with sample data [@GregorPhylopythias2016; @DongReconstructing2017]. The probabilistic binning framework presented in [@sec:synopsis_mglex] makes full use of taxonomic annotations similar to the use of nucleotide composition and contig coverage.

### Overview of binning software

Binning programs emerged and evolved together with metagenome sequencing and assembly, so that their focus changes according to current protocols. Recent programs for complex communities target longer contigs (1 kb or more) but some programs were also designed to bin raw sequencing reads [@VinhTwophase2015; @UlyantsevMetafast2016], for instance by comparison to genome sequence collections or nucleotide composition. Since the latter is unstable for short sequences due to low number of counts [@MchardyAccurate2007], these programs are inherently limited to simple communities and community members with related genome sequences to compare to. Most newer binning programs with applications to complex metagenomes, which are listed in [@tbl:binning_programs], operate on co-assembled contigs, which are constructed using multiple sequenced samples of a microbial community.

| Program | Technique | Sequence information | Published/ updated | License |
| :----------------- | :-------------- | :---------------------- | :----------- | :---------- |
| PhyloPythiaS | Structured Support Vector Machine (SVM) | 5-mers | [-@PatilTaxonomic2011]/ (2012) | proprietary |
| MetaWatt 3.x | Heuristic thresholds | 4-mers, differential coverage | [-@StrousBinning2012]/ (2015) | AFL |
| CONCOCT | Gaussian mixture clustering | 4-mers, differential coverage | [-@AlnebergBinning2014]/ (2015) | BSD |
| GroopM | Biclustering | 4-mers, differential coverage | [-@ImelfortGroopm2014]/ (2016) | GPL |
| MaxBin 2.0 | Expectation-Maximization (EM) clustering | 4-mers, differential coverage | [-@WuMaxbin2014]/ (2016) | BSD |
| MetaBAT | Distance-based clustering | 4-mers, differential coverage | [-@KangMetabat2015]/ (2016) | proprietary |
| PhyloPythiaS+ | Structured Support Vector Machine (SVM) | 5-mers | [-@GregorPhylopythias2016]/ (2014) | proprietary |
| MyCC | Stochastic neighbor embedding | 4-mers, differential coverage | [-@LinAccurate2016]/ (2015) | proprietary |
| COCACOLA | Gaussian mixture clustering | 4-mers, differential coverage, genome co-alignment, paired reads | [-@LuCocacola2016]/ (2016) | GPL |

Table: Contig binning programs with methodology with release dates starting from the year 2011 up to the year 2016. This is a non-exhaustive list with rough methodology descriptions. Some programs employ additional sequence information in post-processing procedures which may be omitted here. A recent overview of binning methods can be found in [@SedlarBioinformatics2017]. {#tbl:binning_programs}

### Binning performance considerations

Binning methods are best judged in the context of their use cases. Clearly, an optimal binning would mean to obtain a single bin for each genome in the community. Suboptimal solutions may contain either multiple smaller bins for a genome or bins with mixed contigs of different genomes. While the objective is clear, it is impossible to obtain perfect genomes for real metagenome data if there is not enough information to discriminate the contigs, especially shorter ones. All of the increasing number of binning methods only produce suboptimal bins, and there is no clear agreement in the metagenomics community how to rate and compare the bins obtained by different methods. Initiatives such as the [Critical Assessment of Metagenome Interpretation (CAMI)](http://cami-challenge.org/) [@SczyrbaCritical2017] work towards establishing a common understanding to judge metagenome binning. Different views on the binning quality are valid as this depends on downstream processing and on the specific research questions. For instance, the estimation of community structure might only require the construction of small-sized bins whereas a hypothetical pathway reconstruction for certain genomes might tolerate excess genes in the corresponding bins and discard all of the remaining bins.

Multiple factors, such as the number and abundances of taxa, their phylogenetic structure, availability of reference genome sequences and computing resources have an impact on binning performance. Binning algorithms are fairly sensitive to the type of community. A method which appears to work well for one ecosystem, may fail if confronted with a completely different metagenome with regard to the number and abundances of genomes and their sequence content. Taxonomic sequence classification methods based on external genome sequences are most sensitive to this problem and this is a direct consequence of the uneven coverage of the tree of life by the reference genomes. In particular communities such as the human gut microbiota are well suited to the classification approach because there are abundant genome data for these microbes. On the contrary, less well studied environments such as a deep sea vent community are likely too exotic for plain classification. Another reason why binning methods perform so differently may be assumptions, for instance pre-set algorithm parameters, which are likely set to achieve good results in specific scenarios.

The broad range of applications involving many different microbial habitats, custom experimental techniques and heterogeneous sequencing platforms makes it difficult to define a state of the art for binning. Nonetheless, general trends can be observed. Recent works which have presented genome bins derived from complex metagenomes often applied clustering in concatenated and transformed feature spaces [@ImelfortGroopm2014; @AlnebergBinning2014; @KangMetabat2015; @LinAccurate2016], which integrate several types of features including nucleotide composition and contig coverage for multiple samples. Nevertheless, deriving high-quality draft genomes today still relies on manual analysis and processing of genome bins [@AlbertsenGenome2013; @ErenAnvi2015].
