\newpage

### A probabilistic model for genome recovery {#sec:synopsis_mglex}

#### Description

The corresponding article in @sec:full_mglex describes a probabilistic model for use in metagenome binning. Such likelihood models are at the core of many popular algorithms, including sequence classification and clustering. While some models exist as fixed parts of contig clustering programs, we developed a new modular, stand-alone and reusable model using a large set of input features. This model is based on parameterized submodels for which maximum likelihood (ML) parameter estimates can be inferred. Besides classification and clustering, we demonstrate alternative applications such as sample size reduction and visualization. The method is available as an open-source Python library and command line program called MLGEX.

##### Introduction

Shotgun sequencing of a microbial community bypasses the need to obtain pure cultures and thus enables novel insights into ecosystems, in particular for those genomes that are inaccessible by cultivation. Since current metagenome assemblies are oftentimes highly fragmented, a process called binning sorts assembled sequences (contigs) according to the underlying genomes. Various programs were written to bin metagenomes, using different methodologies and sequence features. These comprise classification and clustering by consideration of $k$-mer distributions (nucleotide composition), sequence similarity (homology) and assembly read coverage (genome copy number). Coverage information can be very powerful for separating genomes, if multiple samples with varying genome copies are sequenced and co-assembled. However, with a limited number of samples, it remains difficult to reconstuct high-quality bins down to the strain level. Here, we propose a model for metagenome binning, using probabilities to represent natural uncertainty. The model aggregates explicit submodels for read coverage, nucleotide composition and contig similarity to reference sequences (via taxonomic annotation). This design incorporates knowledge about the feature generation process in each submodel, which leads to a robust fit when few data are available. In contrast, other methods frequently apply a data-driven transform before clustering with a single, e.g. Gaussian, model. Our implementation *MGLEX* does not represent an automatic binning solution but a flexible framework for genome recovery.

##### Methods

A classification model is trained to distinguish data of different classes. In probabilistic modeling, training means to determine the model parameters ($\theta$) from example data for a set of different classes. Here, classes correspond to different genomes which make part of a metagenome and the data to be classified are contigs. Hence, we need to provide training sequences for each genome before we can classify unknown contigs.

Let $1\le i\le N$ be an index referring to $N$ contigs resulting from a shotgun metagenomic experiment. For the $i$^th^ contig, we define a joint likelihood ([@eq:mglex_likelihood_aggregate]), which is a weighted product over $M$ independent submodels likelihoods for the different feature types. For the $k$^th^ submodel, $\bm{\mathit{\Theta_k}}$ is the corresponding parameter vector, $\bm{F_{i,k}}$ the feature vector of the $i$^th^ contig and $\alpha_k$ defines the contribution of the respective submodel or feature type. $\beta$ is a free scaling parameter to adjust the smoothness of the aggregate likelihood distribution over the genome bins (bin posterior).

$$
\mathcal{L}(\mathbf{\Theta} \mid \mathbf{F_i})
= \left( \prod_{k=1}^M \mathcal{L}(\bm{\mathit{\Theta_k}} \mid \bm{F_{i,k}})^{\alpha_k} \right)^\beta
$$ {#eq:mglex_likelihood_aggregate}

The model assumes statistical independence of the submodel features. All model parameters are determined from training data, $\mathbf{\Theta}$ using submodel ML estimation, $\bm \alpha$ using the inverse standard deviations of the class log-likelihood distributions ([@fig:mglex_alpha_inference]) and $\beta$ by mean squared error (MSE) minimization ([@fig:mglex_beta_fitting]).

![Procedure for determination of \$\\alpha_k\$ for each submodel. The figure shows a schematic for a single genome and two submodels. The genome's contig log-likelihood distribution is scaled to a standard deviation of one before adding the term in the aggregate model.](figure/mglex_alpha.pdf "Submodel weighting using $\alpha_k$"){#fig:mglex_alpha_inference}

![Model training (err) and test error (Err) as a function of \$\\beta\$ for the complete aggregate model including all submodels and feature types. The solid curve shows the average and the colored shading the standard deviation of the three partitions in cross-validation. The corresponding optimal values for \$\\beta\$ are marked by black dots and vertical lines. The minimum average training error is 0.238 (\$\\beta=2.85\$) and test error is 0.279 at \$\\beta=1.65\$.](figure/mglex_beta.pdf "Training and test error as a function of $\beta$"){#fig:mglex_beta_fitting}

We integrate different submodels $\mathcal{L}(\bm{\mathit{\Theta_k}} \mid \bm{F_{i,k}})$ according to distinct input feature types:

* a Poisson model for absolute read coverage considering multiple samples
* a Binomial model for relative read coverage considering multiple samples
* a frequency model for $k$-mers
* a set of layered frequency models for taxonomic annotation of contigs

The layered frequency model is an adjustment of the standard frequency model for hierarchical labels because the taxonomy represents a tree-like structure ([@fig:mglex_hnbayes_tree]). The listed submodels are kept simple and make independence assumptions to simplify calculations.

![Taxonomy stucture simplified to four levels and eight nodes. A full taxonomy may consist of thousands of nodes. Each taxonomy level uses a frequency model which is assumed independent of the remaining levels.](figure/mglex_tree.pdf "Simplified taxonomy"){#fig:mglex_hnbayes_tree}

We simulated a metagenome (400 genomes with strain heterogeneity) and created short contigs (1 kb) to validate and demonstrate the aggregate model. Differential abundances were produced by simulating Illumina reads (150 bp) for a primary lognormal and three secondary abundance distributions and by mapping the resulting reads to the contigs, introducing typical biases but omitting the actual read assembly. For each genome, we obtained 300 kb of contig data and calculated the read coverage, $5$-mer frequencies and taxonomic annotations as features for the model.

##### Results

Using the simulated metagenome, we applied three-fold cross-validation and checked how well the model classified contigs to the most likely genome (ML) with different combinations of input features. Genome abundance turned out to be the weakest single feature type while taxonomic annotation from local alignment to reference genome sequences was the strongest. However, the aggregation of submodels according to [@eq:mglex_likelihood_aggregate] yielded better performance in all cases. In summary, about 68% of contigs pairs, which were not used for model training, were classified to the same genome using the full set of available submodels. Considering species-level bins, this value increased to 79%, which showed that the model had difficulties to distinguish strains of the same species using the differential abundance values stemming from only four samples in our simulation. The error decreased further when applying soft (not ML) classification, fitting the parameter $\beta$ ([@fig:mglex_beta_fitting]), because each contig could then belong to several genomes with varying class posterior probability. When the model was used to refine the genome bins from two popular automatic binning programs, the quality (adjusted Rand index) improved for both of these programs.

We demonstrated alternative model applications besides classification. Using the likelihood distributions in the training data, we calculated *p*-values, which indicates how extreme a particular contig likelihood is with respect to the training data. With sufficient training data (100 kb in our example), we used the *p*-value to enrich a metagenome sample *in-silico* for a specific genome, so that irrelevant contigs were removed and the overall sample size was reduced. On average, a critical *p*-value of 2.5% led to a sample size reduction of 95%. Such shrinkage may be useful for a more focused analysis or to apply a method with otherwise prohibitive runtime. As a second application example, we derived a probabilistic measure to quantify the similarity between any two genomes or genome bins. The quantity is based on a relative mixture likelihood and may be used to cluster bins hierarchically and to analyze the similarity structure of genome bins (@fig:mglex_tree_bin_comparison). In particular, the method indicates whether the resolution of individual bins is justified with respect to the model and contig data.

![Average linkage clustering of a random subset of 50 out of 400 genomes using probabilistic distances to analyze bin resolution. This example compares the left (blue) tree, which was constructed only with nucleotide composition and taxonomic annotations, with the right (red) tree, which uses all available features. The tip labels were shortened to fit into the figure. The similarity axis is scaled logarithmically to focus on values close to one. Bins which are more than 50\\% similar branch in the outermost ring whereas highly dissimilar bins branch close to the center. ](figure/mglex_bincomparison.pdf "Average linkage clustering of genomes using probabilistic distances"){#fig:mglex_tree_bin_comparison}

##### Discussion

We described an aggregate likelihood model with applications in metagenome binning, for instance classification, genome enrichment and visualization. It builds on specific submodels, each responsible for different feature types. The modular design helps to improve the model and to compute and interpret the results. In comparison to previous methods, we added two new submodels. The first is a binomial model for relative differential read coverage over multiple samples to account for systematic read mapping biases and the second is a layered frequency model for taxonomic annotation, which allows considering external knowledge from reference sequences for sequence binning. We also proposed a new weighting scheme to combine the information of several submodels. The reference implementation called *MGLEX* in its current state lacks support for parallel computations, which will be added later. As the runtime for all submodel ML parameter estimations and sequence classification is linear in the number of contigs, an embedding into clustering algorithms such as the Expectation Maximization (EM) or Markov Chain Monte Carlo (MCMC) algorithms are also feasible. We hope to continue developing the open-source package *MGLEX* as a flexible framework for metagenome analysis and binning, to be integrated into programs and workflows.

\FloatBarrier
